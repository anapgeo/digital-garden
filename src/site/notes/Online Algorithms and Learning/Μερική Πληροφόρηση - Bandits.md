---
{"dg-publish":true,"permalink":"/online-algorithms-and-learning/meriki-pliroforisi-bandits/","created":"2025-03-25T14:58:23.068+02:00","updated":"2025-03-25T15:00:02.695+02:00"}
---



Σε καταστάσεις μερικής πληροφόρησης πρέπει να πάρουμε άμεσα και επαναλαμβανόμενα αποφάσεις σε άγνωστο περιβάλλον. Συνήθως έχουμε ένα σύνολο από δυνατές ενέργειες και ψάχνουμε να βρούμε την καλύτερη. Σε αντίθεση με το μοντέλο των experts, δεν λαμβάνουμε πλήρη πληροφόρηση για κάθε πιθανή ενέργεια. Για παράδειγμα:

- Ποιον δρόμο να επιλέξουμε για να πάμε στη δουλειά μας;
	 -  μονοπάτια = ενέργειες
	 -  ο χρήστης παίρνει feedback από το μονοπάτι που επέλεξε (την καθυστέρηση σε αυτό το μονοπάτι)

-  Posted prices
	-  επιλέγεται μια τιμή (posted price) για κάποιο αντικείμενο προς πώληση
	-  πιθανές τιμές = ενέργειες
	-  μαθαίνουμε μόνο αν αγόρασε ή δεν αγόρασε ο χρήστης, αλλά όχι απαραίτητα αν θα αγόραζε σε κάποια διαφορετική τιμή



Υπάρχουν $Κ$ πιθανές ενέργειες (actions): $1,..,K$

Στον γύρο $t$ :

-  ο αλγόριθμος επιλέγει μια ενέργεια $i_t\in \{1,...,K\}$
-  λαμβάνει απολάβή (reward) $x_{i_t}(t)\in [0,1]$
-  σε $Τ$ γύρους λαμβάνει συνολικό κέρδος $G_A(T)=\sum_{t=1}^{T} x_{i_t}(t)$


Στόχος: Ελαχιστοποίηση Regret

- Συγκρίνει το συνολικό κέρδος του αλγορίθμου $G_A(T)$ με το συνολικό κέρδος της καλύτερης (εκ των υστέρων) ενέργειας  $G_{\max}(T)=\max_i\sum_{t=1}^{T} x_{i_t}(t)$
- Στόχος να ελαχιστοποιηθεί το συνολικό regret: $R_T= G_{\max}(T)- G_A(T)$

### Δημοφιλείς Αλγόριθμοι

[[Online Algorithms and Learning/Αλγόριθμος exponential Weighted average - exploration - exploitation\|Αλγόριθμος exponential Weighted average - exploration - exploitation]]