---
{"dg-publish":true,"permalink":"/online-algorithms-and-learning/provlepsi-me-symvoyli-eidikon-experts-advice/","created":"2025-03-25T14:58:23.050+02:00","updated":"2025-03-25T15:00:05.675+02:00"}
---


## Εισαγωγή

Έστω ότι θέλουμε να προβλέψουμε τον καιρό και απευθυνόμαστε σε κάποιους "ειδικούς"(experts) για συμβουλή. Οι προβλέψεις τους και η πρόβλεψη του αλγορίθμου ανα μέρα καθώς και τα πραγματικά αποτελέσματα δίνονται στον παρακάτω πίνακα

|         | BBC weather | Google Weather | γείτονας | πρόβλεψη αλγορίθμου | τι πραγματικά έγινε |
|---------|-------------|----------------|----------|---------------------|---------------------|
| ημέρα 1 | ν           | ο              | ν        | ν                   | ν                   |
| ημέρα 2 | ν           | ο              | ν        | ο                   | ν                   |
| ημέρα 3 | ο           | ν              | ο        | ν                   | ο                   |
| ημέρα 4 | ο           | ο              | ο        | ο                   | ο                   |

Το ερώτημα που τίθεται είναι: Μπορούμε να προβλέψουμε όσο καλά προέβλεψε ο καλύτερος εκ των υστέρων ειδικός;(Το Google Weather στη συγκεκριμένη περίπτωση)

> Σημείωση: Οι experts δεν έιναι απαραίτητα κάποιοι που έχουν γνώσεις αλλά οποιοσδήποτε έχει γνώμη(όπως ο γείτονας)

## Το μοντέλο

Έστω ότι υπάρχουν Ν experts, και εξετάζουμε T γύρους προβλέψεων. Σε κάθε γύρο t:

-  ο αλγόριθμος δέχεται ένα στιγμιότυπο δεδομένων $x_t \in \mathcal{X}$
-  λαμβάνει μια συμβουλή(advice) $\hat{y}_{it}\in \mathcal{Y}$ απο κάθε ένα από τους N experts
- κάνει μια πρόβλεψη $\hat{y}_t\in \mathcal{Y}$
- μετά την πρόβλεψη μαθαίνει την πραγματική ετικέτα $y_t \in \mathcal{Y}$
- προκύπτει κόστος $L(\hat{y}_t,y_t)$

Στόχος: Ελαχιστοποίηση Regret

-  Συγκρίνει το συνολικό κόστος του αλγορίθμου με το συνολικό κόστος του καλύτερου (εκ των υστέρων) expert
- Άρα το συνολικό κόστος θα είναι $R_T=\sum_{t=1}^{T}L(\hat{y}_t,y_t)-\min_i \sum_{t=1}^{T}L(\hat{y}_{it},y_t)$ (δηλαδή η διαφορά του συνολικού κόστους του αλγορίθμου με το συνολικό κόστος του καλύτερου εκ των υστέρων expert)

## Ντετερμινιστικοι Αλγόριθμοι


### Δημοφιλείς αλγόριθμοι

[[Online Algorithms and Learning/Αλγόριθμος Halving-Αλάνθαστος expert\|Αλγόριθμος Halving-Αλάνθαστος expert]]

[[Online Algorithms and Learning/Αλγόριθμος Weighted Majority-Δεν υπάρχει αλάνθαστος expert\|Αλγόριθμος Weighted Majority-Δεν υπάρχει αλάνθαστος expert]]

[[Online Algorithms and Learning/Αλγόριθμος Εxponential Weighted Αverage\|Αλγόριθμος Εxponential Weighted Αverage]]


### Κάτω Φράγμα Ντετερμινιστικών Αλγορίθμων


>Θεώρημα:Ας θεωρήσουμε $\mathcal{Y}=\{0,1\}$ και $L(\hat{y},y)=|\hat{y}-y|$ , δεν υπάρχει ντετερμινιστικός αλγόριθμος που να μπορεί να επιτύχει υπογραμμικό regret $R_T=o(T)$ για όλες τις ακολουθίες.


Απόδειξη

- Ας θεωρήσουμε δυο experts όπου ο ένας προβλέπει πάντα 1 και ο άλλος προβλέπει πάντα 0
- Ας θεωρήσουμε την εξής adversarial(είδοδος που μας δίνει κάποιος "αντίπαλος") είσοδο:
	-  όταν ο αλγόριθμος προβλέπει $\hat{y}=1$ η είσοδος θα είναι $y=0$
	- όταν ο αλγόριθμος προβλέπει $\hat{y}=0$ η είσοδος θα είναι $y=1$


- Άρα ο αλγόριθμος σφάλλει σε κάθε γύρο, δηλαδή $m_T=T$
- Ο καλύτερος από τους δυο experts σφάλλει το πολύ τις μισές φορές δηλ $m_T^*\leq T/2$
- Άρα $R_T=\sum_{t=1}^{T}L(\hat{y}_t,y_t)-\min_i \sum_{t=1}^{T}L(\hat{y}_{it},y_t)=m_T-m_T^*\leq T/2$



## Τυχαιοποιημένοι Αλγόριθμοι


Δίνεται ένα σύνολο $Ν$ δράσεων (actions) $A =\{1,..,Ν\}$. Πραγματοποιούνται $Τ$ γύροι προβλέψεων όπως και στους ντετερμινιστικούς αλγορίθμους. Σε κάθε γύρο $t$:

- ο αλγόριθμος επιστρέφει μια κατανομή στο σύνολο των δράσεων $Α$, $\mathbf{p}=(p_{1t},...,p_{Nt})$
- Στη συνέχεια λαμβάνει ένα διάνυσμα κόστους $\mathbf{I_t}=(l_{1t},...,l_{Nt})$

- Το αναμενόμενο κόστος του αλγορίθμου στο γύρο $t$ θα είναι $L_t=\sum_{i=1}^{N}l_{it}p_{it}$
- το συνολικό κόστος μετά από T γύρους είναi $\mathcal{L}_T=\sum_{t=1}^{T}L_{t}$

- το συνολικό κόστος μετά από T γύρους που αφορά την δράση $i$ είναι $\mathcal{L}_{T,i}=\sum_{t=1}^{T}l_{it}$
- το ελάχιστο κόστος μιας μεμονωμένης δράσης συμβολίζεται με $\mathcal{L}_T^{\min}=\min_{i\in A} \mathcal{L}_{T,i}$


Στόχος: Ελαχιστοποίηση Regret

- Συγκρίνει το συνολικό κόστος του αλγορίθμου με το συνολικό κόστος του καλύτερης (εκ των υστέρων) δράσης 
- $R_T=\mathcal{L}_T-\mathcal{L}_T^{\min}$


### Δημοφιλείς αλγόριθμοι

[[Online Algorithms and Learning/Τυχαιοποιημένος αλγόριθμος Weighted Majority(Randomized Weighted Majority ή RWM)\|Τυχαιοποιημένος αλγόριθμος Weighted Majority(Randomized Weighted Majority ή RWM)]]


### Κάτω Φράγμα Τυχαιοποιημένων Αλγορίθμων 

> Θεώρημα: Έστω 2 δράσεις, $Ν=2$. Υπάρχει στοχαστική ακολουθία απωλειών για την οποία το αναμενόμενο regret οποιουδήποτε τυχαιοποιημένου άμεσου αλγορίθμου είναι $\mathbf{E}[R_T]\geq \sqrt{T/8}$

Απόδειξη


Ας θεωρήσουμε τις εξής απώλειες για κάθε γύρο t:

-  με πιθανότητα 1/2 εμφανίζονται οι απώλειες $l_{1t}=0,l_{2t}=1$
- με πιθανότητα 1/2 εμφανίζονται οι απώλειες $l_{1t}=1,l_{2t}=0$

Ισοδύναμα:

- με πιθανότητα 1/2 η είσοδος θα είναι $y=0$
- με πιθανότητα 1/2 η είσοδος θα είναι $y=1$

Το αναμενόμενο κόστος οποιουδήποτε randomized αλγορίθμου είναι:

$$
\mathbf{E}[\mathcal{L}_T]= \mathbf{E}[\sum_{t=1}^{T} (p_{1t}l_{1t}+p_{2t}l_{2t})]= \sum_{t=1}^{T} (p_{1t}\mathbf{E}[l_{1t}]+p_{2t}\mathbf{E}[l_{2t}])= \frac{1}{2} \sum_{t=1}^{T}(p_{1t}+p_{2t})=T/2
$$

όπου $p_{1t},p_{2t}$ είναι η κατανομή του τυχαιοποιημένου αλγορίθμου στις δράσεις 1,2


Το αναμενόμενο κόστος της καλύτερης από τις δύο δράσεις είναι $\mathbf{E}[\min \{ L_{T,1},L_{T,2} \}]\geq \frac{T}{2}-b\sqrt{T}$(επειδή αν στρίψουμε ένα δίκαιο νόμισμα T φορές, η μέση τιμή είναι $T/2$ αλλά η τυπική απόκλιση είναι $(1/2)\sqrt{T}$)

Άρα $\mathbf{E}[R_T]=Ω(\sqrt{T})$

\
